#!/usr/bin/env python
import os
import argparse
import requests
import datetime
from urllib.parse import urlparse
from bs4 import BeautifulSoup

## TODO: make this setting configurable
OUTPUT_BASE_DIR = "output/"


def ferch_and_save(urls, includeMetadata):
    for url in urls:
        parsed_url = urlparse(url)

        if parsed_url.scheme == '' or parsed_url.netloc == '':
            print(url + ' is not url, please input url string to fetch (e.g. https://google.com)')
            return

        print(parsed_url.geturl())
        html = requests.get(parsed_url.geturl())

        path = parsed_url.path
        if path == '':
            path = 'ROOT'

        # prepare directory to output result
        output_dir = OUTPUT_BASE_DIR + parsed_url.netloc + path + "/"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        parsed_date = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
        file_name = parsed_date + '.html'

        with open(output_dir + '/' + file_name, 'wb') as f:
            f.write(html.content)

        if includeMetadata:
            soup = BeautifulSoup(html.content, "html.parser")
            links = soup.find_all('a')
            images = soup.find_all('img')
            metadata_file_name = parsed_date + '.metadata'
            with open(output_dir + '/' + metadata_file_name, 'w') as f:
                f.write("number of links:" + str(len(links)))
                f.write("number of images:" + str(len(images)))


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Fetch and save web pages')
    parser.add_argument('urls', metavar='URSs', type=str, nargs='+', help='Urls to fetch and save the page')
    parser.add_argument('--metadata', action='store_true', help='Save metadata as well (number of links, number of images and fetch date)')

    args = parser.parse_args()
    ferch_and_save(args.urls, args.metadata)
